#!/usr/bin/env python3
"""
SISTEMA SIMPLES DE COLETA E REGISTRO DE PRESENÃ‡AS
Coleta logs do Control ID e registra presenÃ§as automaticamente
VERSÃƒO 2: Processa apenas LOGS NOVOS + Eventos expandidos
"""

import requests
import json
import threading
import time
import logging
from datetime import datetime, date, timedelta
from django.utils.dateparse import parse_datetime
from .models import Estagiario, Presenca

logger = logging.getLogger(__name__)

# ConfiguraÃ§Ã£o simples
CONTROL_ID_IP = "192.168.3.40:81"
INTERVALO_COLETA = 30  # segundos
coleta_ativa = False
thread_coleta = None

# Controle de logs jÃ¡ processados - GARANTIA DE UNICIDADE
ultimo_log_processado = {
    'timestamp': None,
    'log_id': None,
    'total_processados': 0
}

# Cache de logs jÃ¡ processados (evita reprocessamento)
logs_processados_cache = set()  # IDs Ãºnicos dos logs jÃ¡ processados
MAX_CACHE_SIZE = 1000  # Limitar tamanho do cache

# NOVO: Cache de estagiÃ¡rios processados neste ciclo (evita entrada+saÃ­da na mesma coleta)
estagiarios_processados_neste_ciclo = set()  # user_ids processados neste ciclo

def fazer_login_control_id():
    """Faz login no Control ID e retorna a sessÃ£o"""
    try:
        url = f"http://{CONTROL_ID_IP}/login.fcgi"
        response = requests.post(url, data={'login': 'admin', 'password': 'admin'}, timeout=10)
        if response.status_code == 200:
            return response.json().get('session')
    except:
        pass
    return None

def gerar_id_unico_log(log):
    """Gera um ID Ãºnico para o log baseado em seus dados principais"""
    user_id = str(log.get('user_id', ''))
    timestamp = str(log.get('time', ''))
    event = str(log.get('event', ''))
    
    # Criar hash Ãºnico baseado nos dados principais
    import hashlib
    dados_log = f"{user_id}|{timestamp}|{event}"
    log_id = hashlib.md5(dados_log.encode()).hexdigest()[:16]
    return log_id

def filtrar_logs_novos(logs):
    """Filtra apenas os logs que ainda nÃ£o foram processados - COM GARANTIA DE UNICIDADE"""
    global ultimo_log_processado, logs_processados_cache
    
    if not logs:
        return []
    
    logs_novos = []
    ultimo_timestamp = ultimo_log_processado['timestamp']
    
    for log in logs:
        # Gerar ID Ãºnico para este log
        log_id_unico = gerar_id_unico_log(log)
        
        # VERIFICAÃ‡ÃƒO 1: Se jÃ¡ foi processado (cache), pular
        if log_id_unico in logs_processados_cache:
            continue
        
        # Extrair timestamp do log
        log_timestamp = log.get('time')
        
        try:
            # Converter timestamp para comparaÃ§Ã£o
            if isinstance(log_timestamp, str):
                try:
                    log_dt = parse_datetime(log_timestamp)
                    if not log_dt:
                        log_dt = datetime.strptime(log_timestamp, '%d/%m/%Y %H:%M:%S')
                except:
                    continue
            elif isinstance(log_timestamp, (int, float)):
                log_dt = datetime.fromtimestamp(log_timestamp) + timedelta(hours=3)
            else:
                continue
            
            # VERIFICAÃ‡ÃƒO 2: Se Ã© o primeiro processamento, marcar e pular (nÃ£o processar histÃ³rico)
            if ultimo_timestamp is None:
                ultimo_log_processado['timestamp'] = log_dt
                ultimo_log_processado['log_id'] = log_id_unico
                continue
            
            # VERIFICAÃ‡ÃƒO 3: Se o log Ã© mais recente que o Ãºltimo processado, Ã© novo
            if log_dt > ultimo_timestamp:
                # Adicionar ID Ãºnico do log
                log['_log_id_unico'] = log_id_unico
                logs_novos.append(log)
        
        except Exception as e:
            logger.error(f"âŒ Erro ao processar timestamp do log: {e}")
            continue
    
    logger.info(f"ğŸ” Encontrados {len(logs_novos)} logs REALMENTE NOVOS de {len(logs)} totais")
    return logs_novos

def buscar_logs_recentes():
    """Busca logs recentes do Control ID"""
    try:
        # Fazer login
        session = fazer_login_control_id()
        if not session:
            logger.error("âŒ NÃ£o conseguiu fazer login no Control ID")
            return []
        
        # Buscar logs
        url = f"http://{CONTROL_ID_IP}/load_objects.fcgi"
        response = requests.post(
            url,
            params={'session': session},
            headers={'Content-Type': 'application/json'},
            json={"object": "access_logs"},
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            logs = data.get('access_logs', [])
            logger.info(f"âœ… Coletados {len(logs)} logs do Control ID")
            return logs
        else:
            logger.error(f"âŒ Erro ao buscar logs: {response.status_code}")
            return []
    
    except Exception as e:
        logger.error(f"âŒ Erro na coleta: {str(e)}")
        return []

def analisar_eventos_control_id():
    """Analisa os eventos encontrados nos logs para mapear padrÃµes"""
    try:
        # Buscar logs
        logs = buscar_logs_recentes()
        
        if not logs:
            logger.info("ğŸ“­ Nenhum log para analisar")
            return
        
        # Contar eventos
        eventos = {}
        user_eventos = {}
        
        for log in logs:
            event = str(log.get('event', 'unknown'))
            user_id = str(log.get('user_id', 'unknown'))
            timestamp = log.get('time', 'unknown')
            
            # Contar eventos gerais
            if event not in eventos:
                eventos[event] = 0
            eventos[event] += 1
            
            # Mapear eventos por usuÃ¡rio
            if user_id not in user_eventos:
                user_eventos[user_id] = {}
            if event not in user_eventos[user_id]:
                user_eventos[user_id][event] = []
            user_eventos[user_id][event].append(timestamp)
        
        # Mostrar anÃ¡lise
        logger.info("ğŸ” ANÃLISE DE EVENTOS CONTROL ID:")
        logger.info(f"ğŸ“Š Total de logs analisados: {len(logs)}")
        
        logger.info("ğŸ“‹ Eventos encontrados:")
        for event, count in sorted(eventos.items()):
            logger.info(f"   Event '{event}': {count} ocorrÃªncias")
        
        # Tentar identificar padrÃµes de entrada/saÃ­da por usuÃ¡rio
        logger.info("ğŸ‘¥ PadrÃµes por usuÃ¡rio (primeiros 3):")
        for i, (user_id, user_events) in enumerate(list(user_eventos.items())[:3]):
            try:
                estagiario = Estagiario.objects.get(control_id_user_id=user_id, ativo=True)
                nome = estagiario.nome
            except:
                nome = f"User {user_id}"
            
            logger.info(f"   {nome}:")
            for event, timestamps in user_events.items():
                logger.info(f"     Event '{event}': {len(timestamps)} vezes")
        
        return eventos, user_eventos
    
    except Exception as e:
        logger.error(f"âŒ Erro na anÃ¡lise: {str(e)}")
        return {}, {}

def processar_log_para_presenca(log):
    """Converte um log do Control ID em presenÃ§a - PROCESSAMENTO ÃšNICO GARANTIDO"""
    global logs_processados_cache
    
    try:
        # Verificar se o log tem ID Ãºnico (deveria ter sido adicionado no filtro)
        log_id_unico = log.get('_log_id_unico')
        if not log_id_unico:
            log_id_unico = gerar_id_unico_log(log)
        
        # GARANTIA FINAL: Verificar se jÃ¡ foi processado
        if log_id_unico in logs_processados_cache:
            logger.warning(f"âš ï¸ Log {log_id_unico} jÃ¡ foi processado - PULANDO")
            return False
        
        # Extrair dados do log
        user_id = str(log.get('user_id', ''))
        timestamp = log.get('time')
        event = str(log.get('event', '')).lower()
        
        if not user_id or not timestamp:
            logger.warning(f"âš ï¸ Log incompleto: user_id={user_id}, timestamp={timestamp}")
            return False
        
        # Converter timestamp
        try:
            if isinstance(timestamp, str):
                log_datetime = parse_datetime(timestamp)
                if not log_datetime:
                    log_datetime = datetime.strptime(timestamp, '%d/%m/%Y %H:%M:%S')
                logger.info(f"[DEBUG] Timestamp string bruto: {timestamp} | Convertido: {log_datetime}")
            else:
                log_datetime = datetime.fromtimestamp(timestamp) + timedelta(hours=3)
                logger.info(f"[DEBUG] Timestamp epoch bruto: {timestamp} | Convertido: {log_datetime}")
        except Exception as e:
            logger.error(f"âŒ Erro ao converter timestamp: {timestamp} - {e}")
            return False
        
        # Buscar estagiÃ¡rio
        try:
            estagiario = Estagiario.objects.get(control_id_user_id=user_id, ativo=True)
        except Estagiario.DoesNotExist:
            logger.warning(f"âš ï¸ EstagiÃ¡rio nÃ£o encontrado para Control ID user_id: {user_id}")
            # MARCAR COMO PROCESSADO mesmo se estagiÃ¡rio nÃ£o encontrado
            logs_processados_cache.add(log_id_unico)
            return False
        
        data_log = log_datetime.date()
        hora_log = log_datetime.time()
        
        logger.info(f"ğŸ”„ Processando [{log_id_unico}]: {estagiario.nome} - Event: {event} - {data_log} {hora_log} - Estado atual: {'PRESENTE' if estagiario.presente else 'AUSENTE'}")
        
        # ==============================
        # LÃ“GICA BASEADA NO CAMPO 'presente' DO ESTAGIÃRIO
        # ==============================
        
        sucesso = False
        
        # SE ESTÃ AUSENTE (default=False) â†’ REGISTRAR ENTRADA (comeÃ§ar a trabalhar)
        if not estagiario.presente:
            logger.info(f"ğŸŸ¢ {estagiario.nome} estÃ¡ AUSENTE â†’ Registrando ENTRADA")
            
            # Criar ou atualizar presenÃ§a APENAS COM ENTRADA
            presenca, criada = Presenca.objects.get_or_create(
                estagiario=estagiario,
                data=data_log,
                defaults={
                    'entrada': hora_log,
                    'saida': None,  # SEM saÃ­da
                    'observacao': f'Entrada automÃ¡tica Control ID (Event: {event}) [ID: {log_id_unico}]'
                }
            )
            
            if not criada:
                # Atualizar presenÃ§a existente APENAS com entrada
                presenca.entrada = hora_log
                presenca.saida = None  # Garantir que saÃ­da estÃ¡ limpa
                presenca.horas = None  # Limpar horas calculadas
                presenca.observacao = f'Entrada: {hora_log} (Event: {event}) [ID: {log_id_unico}]'
                presenca.save()
                logger.info(f"ğŸ”„ PresenÃ§a atualizada - APENAS entrada")
            else:
                logger.info(f"ğŸ“ Nova presenÃ§a criada - APENAS entrada")
            
            # Marcar estagiÃ¡rio como presente (trabalhando)
            estagiario.presente = True
            estagiario.save()
            logger.info(f"âœ… ENTRADA REGISTRADA: {estagiario.nome} Ã s {hora_log} - Agora TRABALHANDO")
            sucesso = True
        
        # SE ESTÃ PRESENTE (presente=True) â†’ REGISTRAR SAÃDA (parar de trabalhar)
        else:
            logger.info(f"ğŸ”´ {estagiario.nome} estÃ¡ PRESENTE â†’ Registrando SAÃDA")
            
            # Buscar presenÃ§a para este dia
            try:
                presenca = Presenca.objects.get(estagiario=estagiario, data=data_log)
                
                # APENAS atualizar com saÃ­da
                presenca.saida = hora_log
                
                # Calcular horas trabalhadas se houver entrada vÃ¡lida
                if presenca.entrada and presenca.entrada != hora_log:
                    entrada_dt = datetime.combine(data_log, presenca.entrada)
                    saida_dt = datetime.combine(data_log, hora_log)
                    horas_trabalhadas = saida_dt - entrada_dt
                    
                    # Verificar se a saÃ­da Ã© depois da entrada
                    if horas_trabalhadas.total_seconds() > 0:
                        hours = int(horas_trabalhadas.total_seconds() // 3600)
                        minutes = int((horas_trabalhadas.total_seconds() % 3600) // 60)
                        presenca.horas = f"{hours:02d}:{minutes:02d}"
                    else:
                        logger.warning(f"âš ï¸ SaÃ­da antes da entrada: {estagiario.nome}")
                        presenca.horas = "00:00"
                else:
                    presenca.horas = "00:00"
                
                presenca.observacao = (presenca.observacao or "") + f' | SaÃ­da: {hora_log} (Event: {event}) [ID: {log_id_unico}]'
                presenca.save()
                
            except Presenca.DoesNotExist:
                # Criar presenÃ§a APENAS com saÃ­da (situaÃ§Ã£o anÃ´mala)
                presenca = Presenca.objects.create(
                    estagiario=estagiario,
                    data=data_log,
                    entrada=None,  # SEM entrada
                    saida=hora_log,
                    horas="00:00",
                    observacao=f'SaÃ­da sem entrada detectada (Event: {event}) [ID: {log_id_unico}]'
                )
                logger.warning(f"âš ï¸ Criada presenÃ§a APENAS com saÃ­da para {estagiario.nome}")
            
            # Marcar estagiÃ¡rio como ausente (nÃ£o trabalhando)
            estagiario.presente = False
            estagiario.save()
            
            horas_trabalhadas_str = presenca.horas if presenca.horas else "00:00"
            logger.info(f"âœ… SAÃDA REGISTRADA: {estagiario.nome} Ã s {hora_log} - Trabalhou {horas_trabalhadas_str}h - Agora AUSENTE")
            sucesso = True
        
        # MARCAR LOG COMO PROCESSADO - GARANTIA DE NÃƒO REPROCESSAMENTO
        logs_processados_cache.add(log_id_unico)
        
        # Limitar tamanho do cache
        if len(logs_processados_cache) > MAX_CACHE_SIZE:
            # Remover os 100 mais antigos (aproximaÃ§Ã£o)
            logs_antigos = list(logs_processados_cache)[:100]
            for log_antigo in logs_antigos:
                logs_processados_cache.discard(log_antigo)
        
        # Atualizar timestamp do Ãºltimo log processado
        global ultimo_log_processado
        ultimo_log_processado['timestamp'] = log_datetime
        ultimo_log_processado['log_id'] = log_id_unico
        
        return sucesso
    
    except Exception as e:
        logger.error(f"âŒ Erro ao processar log: {str(e)}")
        # Marcar como processado mesmo em caso de erro para evitar loops
        if 'log_id_unico' in locals():
            logs_processados_cache.add(log_id_unico)
        return False

def registrar_presencas_dos_logs():
    """FunÃ§Ã£o principal: busca logs NOVOS e registra presenÃ§as - PROCESSAMENTO SEQUENCIAL ÃšNICO"""
    global ultimo_log_processado
    
    # Buscar todos os logs
    try:
        logs = buscar_logs_recentes()
    except Exception as e:
        logger.error(f"âŒ Erro ao buscar logs: {str(e)}")
        return

    if not logs:
        logger.info("ğŸ“­ Nenhum log encontrado")
        return

    # Filtrar apenas logs NOVOS (com garantia de unicidade)
    try:
        logs_novos = filtrar_logs_novos(logs)
    except Exception as e:
        logger.error(f"âŒ Erro ao filtrar logs novos: {str(e)}")
        return

    if not logs_novos:
        logger.info("ğŸ“­ Nenhum log NOVO encontrado")
        return

    logger.info(f"ğŸ”„ Processando {len(logs_novos)} logs NOVOS ÃšNICOS...")

    processados = 0
    entradas = 0
    saidas = 0

    # PROCESSAR UM LOG POR VEZ - SEQUENCIAL
    for i, log in enumerate(logs_novos):
        user_id = str(log.get('user_id', ''))
        log_id = log.get('_log_id_unico', 'sem-id')

        logger.info(f"ğŸ“‹ Processando log {i+1}/{len(logs_novos)} [ID: {log_id}]...")

        # Verificar estado antes do processamento
        estado_antes = None
        nome_estagiario = "Desconhecido"
        try:
            if user_id:
                estagiario = Estagiario.objects.get(control_id_user_id=user_id, ativo=True)
                estado_antes = estagiario.presente
                nome_estagiario = estagiario.nome
        except Exception:
            pass

        # Processar o log (funÃ§Ã£o jÃ¡ tem proteÃ§Ã£o contra duplicatas)
        if processar_log_para_presenca(log):
            processados += 1

            # Verificar estado depois do processamento para contar corretamente
            try:
                if user_id and estado_antes is not None:
                    estagiario = Estagiario.objects.get(control_id_user_id=user_id, ativo=True)
                    estado_depois = estagiario.presente

                    # Se mudou de ausente para presente = entrada
                    if not estado_antes and estado_depois:
                        entradas += 1
                        logger.info(f"   âœ… {nome_estagiario}: AUSENTE â†’ PRESENTE (ENTRADA)")
                    # Se mudou de presente para ausente = saÃ­da
                    elif estado_antes and not estado_depois:
                        saidas += 1
                        logger.info(f"   âœ… {nome_estagiario}: PRESENTE â†’ AUSENTE (SAÃDA)")
                    else:
                        logger.info(f"   âš ï¸ {nome_estagiario}: Estado nÃ£o mudou (possÃ­vel duplicata evitada)")
            except Exception as e:
                logger.error(f"   âŒ Erro ao verificar mudanÃ§a de estado: {e}")
                # NÃ£o incrementa entradas/saidas em caso de erro para evitar inconsistÃªncia
        else:
            logger.info(f"   â­ï¸ Log {log_id} nÃ£o processado (duplicata ou erro)")

    # Atualizar contador total
    ultimo_log_processado['total_processados'] += processados

    if processados > 0:
        logger.info(f"ğŸ‰ RESUMO FINAL:")
        logger.info(f"   ğŸ“Š Logs Ãºnicos processados: {processados}")
        logger.info(f"   ğŸ“¥ Entradas registradas: {entradas}")
        logger.info(f"   ğŸ“¤ SaÃ­das registradas: {saidas}")
        logger.info(f"   ï¿½ Total geral histÃ³rico: {ultimo_log_processado['total_processados']}")
        logger.info(f"   ğŸ§¹ Cache de logs processados: {len(logs_processados_cache)} itens")
    else:
        logger.info("ğŸ“ Logs novos encontrados, mas nenhuma presenÃ§a registrada (possÃ­veis duplicatas evitadas)")

def loop_coleta_automatica():
    """Loop que roda em background coletando e registrando presenÃ§as"""
    global coleta_ativa
    
    logger.info("ğŸš€ Iniciando coleta automÃ¡tica de presenÃ§as...")
    
    while coleta_ativa:
        try:
            logger.info("ğŸ”„ Coletando logs e registrando presenÃ§as...")
            registrar_presencas_dos_logs()
            
        except Exception as e:
            logger.error(f"âŒ Erro no loop: {str(e)}")
        
        # Aguardar intervalo
        time.sleep(INTERVALO_COLETA)

def iniciar_coleta_automatica():
    """Inicia a coleta automÃ¡tica"""
    global coleta_ativa, thread_coleta
    
    if coleta_ativa:
        logger.info("âš ï¸ Coleta jÃ¡ estÃ¡ ativa")
        return
    
    coleta_ativa = True
    thread_coleta = threading.Thread(target=loop_coleta_automatica, daemon=True)
    thread_coleta.start()
    
    logger.info(f"âœ… Coleta automÃ¡tica iniciada! (a cada {INTERVALO_COLETA}s)")

def parar_coleta_automatica():
    """Para a coleta automÃ¡tica"""
    global coleta_ativa
    coleta_ativa = False
    logger.info("ğŸ›‘ Coleta automÃ¡tica parada")

def status_coleta():
    """Retorna o status da coleta"""
    global ultimo_log_processado, logs_processados_cache
    
    return {
        'ativa': coleta_ativa,
        'thread_viva': thread_coleta.is_alive() if thread_coleta else False,
        'intervalo': INTERVALO_COLETA,
        'control_id_ip': CONTROL_ID_IP,
        'ultimo_processamento': {
            'timestamp': ultimo_log_processado['timestamp'].isoformat() if ultimo_log_processado['timestamp'] else None,
            'total_processados': ultimo_log_processado['total_processados']
        },
        'cache_logs': {
            'total_logs_cache': len(logs_processados_cache),
            'max_cache_size': MAX_CACHE_SIZE
        }
    }

def resetar_controle_logs():
    """Reseta o controle de logs processados (para testes)"""
    global ultimo_log_processado, logs_processados_cache
    ultimo_log_processado = {
        'timestamp': None,
        'log_id': None,
        'total_processados': 0
    }
    logs_processados_cache.clear()
    logger.info("ğŸ”„ Controle de logs resetado - cache limpo - prÃ³xima execuÃ§Ã£o processarÃ¡ tudo como novo")

